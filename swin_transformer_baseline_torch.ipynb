{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "기본적인 Pytorch Module 들을 import 한다.\n",
    "torch는 1.12.1\n",
    "'''\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import einsum\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from einops import rearrange, repeat\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator #Pytorch-Ignite를 통해서 model을 훈련시키고 업데이트 하는 과정을 단순화 시킨다. \n",
    "import ignite.metrics\n",
    "import ignite.contrib.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='./data'  #data path 지정\n",
    "\n",
    "IMAGE_SIZE = 32 #Imgae Size 지정, Cifar10이니 이미지 Size 32\n",
    "\n",
    "NUM_CLASSES = 10 #cifar10이니 10개의 클래스, cifar100이면 100, IMAGENET-1k는 1000\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") #Cuda 사용\n",
    "#사용 GPU는 Tesla V100 32G\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXG0lEQVR4nO2de4xdV3XGv33u+zEzd962Y4fYsUlCQkIQKaUIigCVVAUqAaJtEFWrUgmB2j8A0Yf4g6qloFKpD7VUVSvoA1ChUlUEqmiU0oinaBGElEBecvx+ZWY8M5479313/7g37WDtb9meJPay/f0kK5Oz7j53n33Pd8/MWnutFWKMEEL4I7vSExBCpJE4hXCKxCmEUyROIZwicQrhFIlTCKdInE4JIdwUQoghhPxlft8HQwjveh7OeyiE8Hpie1UI4bHn+j2vdq5rcYYQfjGE8O0QQjOEcGb883tCCOFKz+1CWDf7JZzjwyGETz9Xc9ouMcavxRhvudLz8MZ1K84QwvsB/BmAjwPYAWARwLsBvBJAkYzJXbYJPksu9xNXPA/EGK+7fwCmADQBvPUCr/s7AH8F4N/Gr389gNsAPAhgFcAjAN685fUPAnjXlv//FQBf3/L/EaMvgCcAnAXwlwDC2JYD8McAlgAcBPDe8evziXn9I4AhgBaADQAfBHDT+PW/BuAIgK8CeA2AY+eNPTS+jnsBdAH0xuf4/pZr+H0A3wBwDsD9AOYucl3nAHxpvDYrAL4GINvyvh8A8DCANQCfA1Ae235snuPX/g6AH47X6VPPvPZ6+ne9PjlfAaAE4AsX8dr7AHwEwASAbwP4IkY37AKA3wDwmRDCpfxK9kYA9wC4C8DbAbxhfPzXx7a7AbwMwNvYCWKM78RIgG+KMdZjjH+0xfzTGH2BvCE5+P/P8WUAfwjgc+Nz3LXFfB+AX8XoGosYiQoAEEJ4OIRwHznt+wEcAzCP0W8iv4vRF8YzvB2jL4W9AO7E6MuL8Y7xNdwM4IUAPmRdz7XI9SrOOQBLMcb+MwdCCN8MIayGEFohhFdvee0XYozfiDEOAbwEQB3Ax2KM3RjjVzB6UvzSJbz3x2KMqzHGIwD+c3xOYHTj/mmM8WiMcQXAR7d5bR+OMTZjjK1tjgeAT8UYHx+f4/Nb5ogY450xxs+ScT0AOwG8IMbYi6O/JbeK889jjCfG1/fFredN8Bdb1uIjuLQ1via4XsW5DGBu699lMcafijE2xrat63J0y8+7ABwdC/UZDgO44RLe+9SWnzcxEvv/nfu8826Hoxd+yQVhc7wQHwfwJID7QwgHQwi//SzOe/5a7LrIOVwzXK/i/BaADoCfv4jXbv3mPwFgTwhh67rdCOD4+OcmgOoW245LmNNJAHvOO+/Fzosd/7H5jB1a8xdxjm0RYzwXY3x/jHEfgDcBeF8I4XXbPN35a3HiWU/wKuO6FGeMcRXA7wH4RAjhbSGEegghCyG8BEDNGPptjG74D4YQCiGE12B0E/7T2P4QgLeEEKohhP0YOWculs8D+M0Qwu4QwjSA858653MawL4LvOZxAOUQws+FEAoY/d1WOu8cN533ZbNtQghvDCHsH4ei1gEMxv+2w3vHazGD0d+un3su5ng1cV2KEwDGTpT3YeTpPIPRjfrXAH4LwDfJmC6ANwP4WYy8qp8A8MsxxkfHL/kTjDygpwH8PYDPXMKU/gbAvwP4PoDvAviXC7z+owA+NP47+QOpF8QY1wC8B8DfYvR0b2LksHmGfx7/dzmE8N2LmWQI4ZEQwjuI+QCABzDy/n4LwCdijA9ezHkTfBYjx9vB8b8/2OZ5rlrCj/+9LsSVJ4RwCKOQ1ANXei5Xkuv2ySmEdyROIZyiX2uFcIqenEI4xdwcvbS0RB+r/X6fmXAVJHVsCzfXZf2yY9jMYeRrOhqjMjboQm8WhtxEbBF87YPxjHk+fjPczn1gzWNxcTF5Qj05hXCKxCmEUyROIZwicQrhFIlTCKdInEI4xQyl5HJXTcmcy4KbUIpBGPIkEDOokKWvbWiEMBCN+yMaoY+MzySAhVms2V/doRSGnpxCOEXiFMIpEqcQTpE4hXCKxCmEUyROIZxihlIs9+/1mAd6Oa/ZdNdb84g848OMitCwCP/+7vR4ZlK+UOBvNuBzzIXtrLFxzU5QKEWIawiJUwinSJxCOEXiFMIpEqcQTjG9tZbH8GrYBM646j3NxtIPLA/7kA/sD9Mez16fb6R/4uBBalvcsUBtw26X2uZnppPHyyXu/R1eBZ/ndvSiJ6cQTpE4hXCKxCmEUyROIZwicQrhFIlTCKc8Lxvfr+Ywi8V2r+u5D93weeQKRWobGHV9Whud5PHVtSYdc3pphdoqE7xB+OzEBLVlpMm21XKBtXB4VlhhxOf+3ZLoySmEUyROIZwicQrhFIlTCKdInEI4ReIUwilmKCUjJfoBO8PhcmJEBy7QfyCNFS7JthlKGRjO9yHJBsnl+Pdmt9ujtqeX16ltvdmmtlYnnX3S3EyHWAAgK1WprdnimSf1Kv9g+sTEA0Rm1ON54XKFCvXkFMIpEqcQTpE4hXCKxCmEUyROIZwicQrhFDOU0txsceOQu8PzpCN2NMbk8rxLsmULRvl+FmbJhtv7TsqsfATDvb7R4SEMlrFSyfOPpm20QThphFLOnOU21sG6x2IbADbPbfD3MjJWjh0/SW0vOrAvefzmm3bTMblodPM2W1cY94EVLSE2q5OEee/QMUIIl0icQjhF4hTCKRKnEE6ROIVwisQphFPMUMpqi2ck1Ku8gFOWT/e1GAx5CMCMbhhe6Jxhy0gsJWTb/E7aZlGzUyePU9vMzEzyeKXM8zA67U1qq5b4uB3zc9QWySI3N3kYqFbk79Vt8zBcLuMFuTY66Xuub/bt4bexXVzNOuc2Rm2zGTlDT04hnCJxCuEUiVMIp0icQjhF4hTCKaa3Nj85S20Dw+PZy8hG9cA3KFu2wZDbMsuDSmxxO8WFYNcrMsotod/lXu/ANm0bnu2G0eqg1zOuLce7Q1fr6RYJlrc25EqGjS9IqcLnEchC9kmbBgCIVjeGbX5mVgEqNnv7dJd+z+nJKYRTJE4hnCJxCuEUiVMIp0icQjhF4hTCKWYo5ZP/8GlqC0Y9oALZ+F6fKNMx+/feSG333PkiassbXy+sZpHZsdvyrxu7oftG6GOabG4HgGIpvSZsIzoAFIs8hDE7zestRXBbnmxiLxq1jFDgn2e7z9djdf0st62tJY+fW1ulY3pWrSujsM/sbIPaDuxP1zICgEIxvSZWtISFiCz05BTCKRKnEE6ROIVwisQphFMkTiGcInEK4RQzlNIyMhK6LW4rEPf7ubSXHABQNVz2g9tupbZ25B2UMxJKKRUrdIzlDh9YIRgjzDI1M09ttFu2kfXTJd2wASBn1PWBkdnBzjg0sjMOHT5IbcfPnKG2leVlamu10mGRQYeHZrpGF+1Oh9db2r1nkdpu3MPbP9RIKMXKZLFCYww9OYVwisQphFMkTiGcInEK4RSJUwinSJxCOMUMpbz9LW+lto6RCVCrpEMVwXA1V6h7GghGAaf1daNbc7+XPF7I82yKfIXbotFhu9Xj7vw45NeWkZAJy+wBgLwxj0LBaDGQXXooqGeEj9rD9PoCQG2yTm3TjQa1Dbrpc5ZzPPy1usxjdMeOH6K2/Xv3U1suM0J7ZE1yRjhN7RiEuIaQOIVwisQphFMkTiGcInEK4RSJUwinmKGUYc/IfjB0zRz99SLv8VEp86JVrTYPl2z2eB+VQwcPJY8XjayUG/e+gNqeOnqC2r705f+gtl7GwyJl0om6aqxHzQj3TE1OUltjKt0PBQDuvvvO5PH5uWk65ubdN1BbFni4J2dkx3Tb6b4yeSO00VrgBdR27Wxw2w07qW0w4PfV5mY63MNCiICZEETRk1MIp0icQjhF4hTCKRKnEE6ROIVwisQphFPMUMq/fvF+ahv2eEZChnSGRr1YpWMmjBDATQd4saX5WZ79MLsz3X9lZm6BjinXeJhi9UeHqe0HPzpKbS0jJYElmOSNDJ4JY477b+ShoFf8xEupbbaWDrPUcvwWiUbNqm6XF+TqD9LhEgDYJD1RegN+v1WqfD0aDR6+O33qNLUtLa3w96ulQyaLO/h9Va3y0NjcZHrt9eQUwikSpxBOkTiFcIrEKYRTJE4hnGJ6a7/zvR9QW7nAy/53O+mN6oUi/y54+U/eQ22Hj3NP6PJJasIdt9+ePF40No5vdngtoIKxGf3ul6Y3jgNAu8W9k8VC+iM4sG8vHXP7bbdQ2665BrVNVvnG7GE7fd1HTz1Nx5w5yztUn1zi45obTWpbXV1NHu/2+BqyTtMA7xwOAIM+94j3etzbXG2kvat3IH2/AcCUkXSwb0e6XYeenEI4ReIUwikSpxBOkTiFcIrEKYRTJE4hnGKGUp4+xjd6z0zz2jI37E5vAH7RnQfomEKJ76J+5KH/orbFMneV10O6DsyZJR5/qU1OUdvsJH+vN9/7amrLjAIyU1Pp95ubnaVjVlZ4Z+inDj9BbWurvBbT+tq55PFz67wz9GqTh0RW1nmLhL6RNFEopOstFUu8DlOWM9Z3kt9XDaMtxPQCD32UqukEjmKFJ3ZsGJ3gGXpyCuEUiVMIp0icQjhF4hTCKRKnEE6ROIVwihlKOf74D6lt3ehc/MafeXfy+L33vo6OeeArvF7RAskCAICFqtHiIZ92o5eNVtmLU7yW0YRhKxt1bPpGPSCWNdEf8Dmeeuw4tR05w+vidHtGLaNyeh0nJnirg4UyDx30SIfqC1EopkMmOSNcYtkmJvi9M0lq94zOyUMwG810eOn06SU6pt3mISm87K7kYT05hXCKxCmEUyROIZwicQrhFIlTCKdInEI4xQyltDd51sGL77qD2l77utcmj882eKbFK19uZHVkRmuCAi+6NVlPhwdyRR72yBtdr6MxjyFpQQEAa2d5FslkPj3/Ie0PDuy7ha/9wu4XUtvKWZ6VMkEyNHoDfs0h8u/2QsbnPxzyMFG7nc7e2Ghu0DFxyLtQb2zycUdP8uykdouHPnqb6Tla3bCrNX6fMvTkFMIpEqcQTpE4hXCKxCmEUyROIZwicQrhFDOUsu/W9G55APiFd76L2jYH6cyCx57kGRPDwAs4lY0MmJ7RXnlllbi2h9xNPhi0qC0YqzUE7+Vxbj1dPAsAcqfT2RsnzpyhYzodnvExbPMeHzUjg+fgE8eSx586coSOCXn+mc3M8bBZt8PXam0tXRhseYlnfEQjhJFlPGwTDFutwkNqDZLBUzZ66bQ2+H3F0JNTCKdInEI4ReIUwikSpxBOkTiFcIrprX3rffdR2/SO3dT2/R+kPX9do65M19gMPTA2gcehUVsGaU9uMGr6DIzaPdEYl5lfc0YH5X76/ZaWuWe73+eeP8MBicZkg9q63bQHdWWZJz8gxz+XpSXefqDT4/Pvk7YFgy5PLMgZna2rZd6BvWTVJerza+u22X3MvcaVGk+2YOjJKYRTJE4hnCJxCuEUiVMIp0icQjhF4hTCKWYo5XsPfYfaHv6fh6gtIL1pOJfjG6XzRi2gXN5yQ/Nz5oirP1/k30llo1M267oMAMUSn39m1CXKxfQ5J4u8c3hWMhIBctyd3x7wTfF9Eu0pki7OANDb5BvYN5u8XlG3z8cF1vXaiFV1jTpHA9I6AQCa5/g8qkZ4Zn4qvf55oyUH6TJhoienEE6ROIVwisQphFMkTiGcInEK4RSJUwinmKGUr3/1AWrbXF+ltmIh7X6vVHknYWsqucht0fh+yQoslMLrDpVJp2nArhFTNLo856u8nk65OJU+X2aEnYyv1FDm1xaCkR3TSWd9dEiWCAD0ejxTZGh0D4cxjzzL4DHaO6DE12qqZtn4fVWvGNkshfS1FQLPugoDHrZh6MkphFMkTiGcInEK4RSJUwinSJxCOEXiFMIpZihlcX6S2k62nqa2wWA1eXxyZoZPxGjHsL50ltrOrfMCVL1B2tU/NLIiolFozMQIfRQrC/z9Cuk17hu9HzIjllI1MmBqFR7uGfRIxsqQhz1Q4vMIVrjKyPiokHDVDOlSDgC76zxEt3vnHLUZSSTotHkLjSymw0v5HL/mxiT/XOj7XPIIIcRlQeIUwikSpxBOkTiFcIrEKYRTJE4hnGKGUmKPF0eaqvFd++faaVdzb7BBx9xy6+18Hjt5CObppWVqO7Oc7oa8wTpeA9jctLpe8wJZwz7P3qjl05knAHDrnTcnj58wumE/bWQEtbo8tNRq8x4lrK9MqcA/55pR8KxR46GD+UaD2nbs2pE8vv+GRTpmocQzVjaMQmMrKzwcmDOKwFVr6eJr9Ql+zbOzvGAbQ09OIZwicQrhFIlTCKdInEI4ReIUwimmt3b5RLpDNQAMetw72SJ1YDaPHqFjZoxWDXNlvum50OHe1Qpp89zK8c3cMXKPrNW52KqLs9lKe40B4FX3pL3Ut9/2YjrmyJHD1La8ypMEOqROEAC6wT1v1O6pZPya54x6S40a/zwHZI1PLfF757Glk9QWjM7Wkwu8tlNlkm+mr06k5z8zx89Xn+Iee4aenEI4ReIUwikSpxBOkTiFcIrEKYRTJE4hnGKGUnYYG86PHeFhln6HhCMCD1M89fhj1LZW5LVvrG+X5jBdHr/Z52Xzh8bmdrBWAQBygdePserRfPcb9yePv6bGu1ffYXR5bk3xEMCwz0NBoZ++7naXh8zWjBYDLOkAAA4/eprallrpjertAl/fygK/T6d3NKitNMnvq5zRjqE6la77VKryEFHImVJLoienEE6ROIVwisQphFMkTiGcInEK4RSJUwinmP7dPQf2UNu6UZuleYy50bk7vG2EMFb6vEVC0Whb0CUZJoNoZJfE7bVjCNHqKM3HPfnwfyePHz3Hwz3zGa9VEyMP9wyMEMwGyeA5RVoPAMCTRkbQMaPlxWaVf2YTe3Ymjy/ufQEdU27wtiHIjFs8x9ejXuehrCrJWMkKPBMnhkt/DurJKYRTJE4hnCJxCuEUiVMIp0icQjhF4hTCKWYoZXKa7/afX+Tdmk+SUIoRUTAbKHeMwlo9YxwLmQywze7VBtHIWLEuvNdKt0hoLvFWAVmpQW25Dg99nDDW8SGkQx9P5vlaNeu8KFttN28/ML9rF7XNzqfbLpRqPIOka6x9NEJjpTwvXpazbLm0LZc3upGTMRZ6cgrhFIlTCKdInEI4ReIUwikSpxBOkTiFcIoZSqkYPUpKRi+MAukKPOhxt7aR1IG+0YcEVliEDbPezMjqsBgaqSfRsG0M0/N/tGt0FS/yrJRH27x41iN93vV6hRS7mtmzl47ZeRMPiTSM4nAlo3hZNkyvVc8IieTyvBhXzsgUyRf5uJDxz2wwSIekgvE5Z8pKEeLaQeIUwikSpxBOkTiFcIrEKYRTJE4hnGKGUnpG0a1mi/f/mGiUk8fbTV70aUBCCgAwMNzQAyvyQYzBqO9l585wohGeiUafjGaWXuOvd9fomMObRjG0Kl+r/CIv2Lbjhvnk8b3zc3TM7BRvs54Z4ZKmkUXSJmGzvJElUjbCemWjf0m+mL5PAaBc4VkwpXJ6XKHAs3S2g56cQjhF4hTCKRKnEE6ROIVwisQphFMu4K3l3tVckXvcpufTHrJenW807hub4g0TeoaXNxJvLek8AAAIhrfW2thsbW5Hnnvx8nmy0dvorNyZ4pvK903x2k7TM7xtQX0yfSvUq9xLWirz26dtdNHuGrWMIvF45grGrWqtvWErGBvfrRpCBTIXVlsIuECNKYKenEI4ReIUwikSpxBOkTiFcIrEKYRTJE4hnGKGUnIF7oZuzPCNzXWy+XrQ5e5kK5TSHxjhEiP0kZGuxsH4TsqsOjAZd5VneWPDeYFfd4W47Ccm+IbtxfoUtdVLvL5Qzag9VCylQxhdYy/3BqkVBQAtI2nCSmQok7BT0UgesEIiVhuEYHT6tjqEd7vpruPFIu9GXiyoHYMQ1wwSpxBOkTiFcIrEKYRTJE4hnCJxCuGUYLmMhRBXDj05hXCKxCmEUyROIZwicQrhFIlTCKdInEI45X8BGrqw4ED+dHcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float)\n",
    "])\n",
    "\n",
    "train_dset = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_transform)#dataset 준비\n",
    "test_dset = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "def dataset_show_image(dset, idx): #dataset속 data 확인하는 함수 \n",
    "    X, Y = dset[idx]\n",
    "    title = \"Ground truth: {}\".format(dset.classes[Y])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(np.moveaxis(X.numpy(), 0, -1))\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "dataset_show_image(test_dset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                           num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                          num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.residual = nn.Sequential(*layers)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.gamma * self.residual(x)\n",
    "class GlobalAvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.mean(dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftedWindowAttention(nn.Module):\n",
    "    def __init__(self, dim, head_dim, shape, window_size, shift_size=0):\n",
    "        super().__init__()\n",
    "        self.heads = dim // head_dim\n",
    "        self.head_dim = head_dim\n",
    "        self.scale = head_dim**-0.5\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        \n",
    "        self.to_qkv = nn.Linear(dim, dim * 3)\n",
    "        self.unifyheads = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.pos_enc = nn.Parameter(torch.Tensor(self.heads, (2 * window_size - 1)**2))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(window_size))\n",
    "        \n",
    "        if shift_size > 0:\n",
    "            self.register_buffer(\"mask\", self.generate_mask(shape, window_size, shift_size))\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        shift_size, window_size = self.shift_size, self.window_size\n",
    "        \n",
    "        x = self.to_windows(x, self.shape, window_size, shift_size) # partition into windows\n",
    "        \n",
    "        # self attention\n",
    "        qkv = self.to_qkv(x).unflatten(-1, (3, self.heads, self.head_dim)).transpose(-2, 1)\n",
    "        queries, keys, values = qkv.unbind(dim=2)\n",
    "        \n",
    "        att = queries @ keys.transpose(-2, -1)\n",
    "        \n",
    "        att = att * self.scale + self.get_rel_pos_enc(window_size) # add relative positon encoding\n",
    "        \n",
    "        # masking\n",
    "        if shift_size > 0:\n",
    "            att = self.mask_attention(att)\n",
    "        \n",
    "        att = F.softmax(att, dim=-1)\n",
    "        \n",
    "        x = att @ values\n",
    "        x = x.transpose(1, 2).contiguous().flatten(-2, -1) # move head back\n",
    "        x = self.unifyheads(x)\n",
    "        \n",
    "        x = self.from_windows(x, self.shape, window_size, shift_size) # undo partitioning into windows\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def to_windows(self, x, shape, window_size, shift_size):\n",
    "        x = x.unflatten(1, shape)\n",
    "        if shift_size > 0:\n",
    "            x = x.roll((-shift_size, -shift_size), dims=(1, 2))\n",
    "        x = self.split_windows(x, window_size)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def from_windows(self, x, shape, window_size, shift_size):\n",
    "        x = self.merge_windows(x, shape, window_size) \n",
    "        if shift_size > 0:\n",
    "            x = x.roll((shift_size, shift_size), dims=(1, 2))\n",
    "        x = x.flatten(1, 2)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def mask_attention(self, att):\n",
    "        num_win = self.mask.size(1)\n",
    "        att = att.unflatten(0, (att.size(0) // num_win, num_win))\n",
    "        att = att.masked_fill(self.mask, float('-inf'))\n",
    "        att = att.flatten(0, 1)\n",
    "        return att\n",
    "    \n",
    "    \n",
    "    def get_rel_pos_enc(self, window_size):\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.pos_enc.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (window_size**2, window_size**2))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    \n",
    "    # For explanation of mask regions see Figure 4 in the article\n",
    "    @staticmethod\n",
    "    def generate_mask(shape, window_size, shift_size):\n",
    "        region_mask = torch.zeros(1, *shape, 1)\n",
    "        slices = [slice(0, -window_size), slice(-window_size, -shift_size), slice(-shift_size, None)]\n",
    "        \n",
    "        region_num = 0\n",
    "        for i in slices:\n",
    "            for j in slices:\n",
    "                region_mask[:, i, j, :] = region_num\n",
    "                region_num += 1\n",
    "\n",
    "        mask_windows = ShiftedWindowAttention.split_windows(region_mask, window_size).squeeze(-1)\n",
    "        diff_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "        mask = diff_mask != 0\n",
    "        mask = mask.unsqueeze(1).unsqueeze(0) # add heads and batch dimension\n",
    "        return mask\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def split_windows(x, window_size):\n",
    "        n_h, n_w = x.size(1) // window_size, x.size(2) // window_size\n",
    "        x = x.unflatten(1, (n_h, window_size)).unflatten(-2, (n_w, window_size)) # split into windows\n",
    "        x = x.transpose(2, 3).flatten(0, 2) # merge batch and window numbers\n",
    "        x = x.flatten(-3, -2)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def merge_windows(x, shape, window_size):\n",
    "        n_h, n_w = shape[0] // window_size, shape[1] // window_size\n",
    "        b = x.size(0) // (n_h * n_w)\n",
    "        x = x.unflatten(1, (window_size, window_size))\n",
    "        x = x.unflatten(0, (b, n_h, n_w)).transpose(2, 3) # separate batch and window numbers\n",
    "        x = x.flatten(1, 2).flatten(-3, -2) # merge windows\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_indices(window_size):\n",
    "        x = torch.arange(window_size, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(x, x, x, x, indexing='ij')\n",
    "        indices = (y1 - y2 + window_size - 1) * (2 * window_size - 1) + x1 - x2 + window_size - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Sequential):\n",
    "    def __init__(self, dim, mult=4):\n",
    "        hidden_dim = dim * mult\n",
    "        super().__init__(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim)   \n",
    "        )\n",
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, dim, head_dim, shape, window_size, shift_size=0, p_drop=0.):\n",
    "        super().__init__(\n",
    "            Residual(\n",
    "                nn.LayerNorm(dim),\n",
    "                ShiftedWindowAttention(dim, head_dim, shape, window_size, shift_size),\n",
    "                nn.Dropout(p_drop)\n",
    "            ),\n",
    "            Residual(\n",
    "                nn.LayerNorm(dim),\n",
    "                FeedForward(dim),\n",
    "                nn.Dropout(p_drop)\n",
    "            )\n",
    "        )\n",
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self.norm = nn.LayerNorm(4 * in_dim)\n",
    "        self.reduction = nn.Linear(4 * in_dim, out_dim, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unflatten(1, self.shape).movedim(-1, 1)\n",
    "        x = F.unfold(x, kernel_size=2, stride=2).movedim(1, -1)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage(nn.Sequential):\n",
    "    def __init__(self, num_blocks, in_dim, out_dim, head_dim, shape, window_size, p_drop=0.):\n",
    "        if out_dim != in_dim:\n",
    "            layers = [PatchMerging(in_dim, out_dim, shape)]\n",
    "            shape = (shape[0] // 2, shape[1] // 2)\n",
    "        else:\n",
    "            layers = []\n",
    "        \n",
    "        shift_size = window_size // 2\n",
    "        layers += [TransformerBlock(out_dim, head_dim, shape, window_size, 0 if (num % 2 == 0) else shift_size,\n",
    "                                    p_drop) for num in range(num_blocks)]\n",
    "        \n",
    "        super().__init__(*layers)\n",
    "class StageStack(nn.Sequential):\n",
    "    def __init__(self, num_blocks_list, dims, head_dim, shape, window_size, p_drop=0.):\n",
    "        layers = []\n",
    "        in_dim = dims[0]\n",
    "        for num, out_dim in zip(num_blocks_list, dims[1:]):\n",
    "            layers.append(Stage(num, in_dim, out_dim, head_dim, shape, window_size, p_drop))\n",
    "            if in_dim != out_dim:\n",
    "                shape = (shape[0] // 2, shape[1] // 2)\n",
    "                in_dim = out_dim\n",
    "        \n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToPatches(nn.Module):\n",
    "    def __init__(self, in_channels, dim, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        patch_dim = in_channels * patch_size**2\n",
    "        self.proj = nn.Linear(patch_dim, dim)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.unfold(x, kernel_size=self.patch_size, stride=self.patch_size).movedim(1, -1)\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "class AddPositionEmbedding(nn.Module):\n",
    "    def __init__(self, dim, num_patches):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.Tensor(num_patches, dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pos_embedding\n",
    "class ToEmbedding(nn.Sequential):\n",
    "    def __init__(self, in_channels, dim, patch_size, num_patches, p_drop=0.):\n",
    "        super().__init__(\n",
    "            ToPatches(in_channels, dim, patch_size),\n",
    "            AddPositionEmbedding(dim, num_patches),\n",
    "            nn.Dropout(p_drop)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Sequential):\n",
    "    def __init__(self, dim, classes, p_drop=0.):\n",
    "        super().__init__(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.GELU(),\n",
    "            GlobalAvgPool(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(dim, classes)\n",
    "        )\n",
    "class SwinTransformer(nn.Sequential):\n",
    "    def __init__(self, classes, image_size, num_blocks_list, dims, head_dim, patch_size, window_size,\n",
    "                 in_channels=3, emb_p_drop=0., trans_p_drop=0., head_p_drop=0.):\n",
    "        reduced_size = image_size // patch_size\n",
    "        shape = (reduced_size, reduced_size)\n",
    "        num_patches = shape[0] * shape[1]\n",
    "        \n",
    "        super().__init__(\n",
    "            ToEmbedding(in_channels, dims[0], patch_size, num_patches, emb_p_drop),\n",
    "            StageStack(num_blocks_list, dims, head_dim, shape, window_size, trans_p_drop),\n",
    "            Head(dims[-1], classes, head_p_drop)\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.weight, 1.)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, AddPositionEmbedding):\n",
    "                nn.init.normal_(m.pos_embedding, mean=0.0, std=0.02)\n",
    "            elif isinstance(m, ShiftedWindowAttention):\n",
    "                nn.init.normal_(m.pos_enc, mean=0.0, std=0.02)\n",
    "            elif isinstance(m, Residual):\n",
    "                nn.init.zeros_(m.gamma)\n",
    "    \n",
    "    def separate_parameters(self):\n",
    "        parameters_decay = set()\n",
    "        parameters_no_decay = set()\n",
    "        modules_weight_decay = (nn.Linear, )\n",
    "        modules_no_weight_decay = (nn.LayerNorm,)\n",
    "\n",
    "        for m_name, m in self.named_modules():\n",
    "            for param_name, param in m.named_parameters():\n",
    "                full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "                if isinstance(m, modules_no_weight_decay):\n",
    "                    parameters_no_decay.add(full_param_name)\n",
    "                elif param_name.endswith(\"bias\"):\n",
    "                    parameters_no_decay.add(full_param_name)\n",
    "                elif isinstance(m, Residual) and param_name.endswith(\"gamma\"):\n",
    "                    parameters_no_decay.add(full_param_name)\n",
    "                elif isinstance(m, AddPositionEmbedding) and param_name.endswith(\"pos_embedding\"):\n",
    "                    parameters_no_decay.add(full_param_name)\n",
    "                elif isinstance(m, ShiftedWindowAttention) and param_name.endswith(\"pos_enc\"):\n",
    "                    parameters_no_decay.add(full_param_name)\n",
    "                elif isinstance(m, modules_weight_decay):\n",
    "                    parameters_decay.add(full_param_name)\n",
    "\n",
    "        # sanity check\n",
    "        assert len(parameters_decay & parameters_no_decay) == 0\n",
    "        assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "        return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinTransformer(NUM_CLASSES, IMAGE_SIZE,\n",
    "                        num_blocks_list=[4, 4], dims=[128, 128, 256],\n",
    "                        head_dim=32, patch_size=2, window_size=4,\n",
    "                        emb_p_drop=0., trans_p_drop=0., head_p_drop=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = SwinTransformer(NUM_CLASSES, IMAGE_SIZE,\\n                        num_blocks_list=[4, 4], dims=[128, 128, 256],\\n                        head_dim=32, patch_size=2, window_size=4,\\n                        emb_p_drop=0., trans_p_drop=0., head_p_drop=0.3)\\n                        '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = SwinTransformer(NUM_CLASSES, IMAGE_SIZE,\n",
    "                        num_blocks_list=[4, 4], dims=[128, 128, 256],\n",
    "                        head_dim=32, patch_size=2, window_size=4,\n",
    "                        emb_p_drop=0., trans_p_drop=0., head_p_drop=0.3)\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1             [-1, 256, 128]           1,664\n",
      "         LayerNorm-2             [-1, 256, 128]             256\n",
      "         ToPatches-3             [-1, 256, 128]               0\n",
      "AddPositionEmbedding-4             [-1, 256, 128]               0\n",
      "           Dropout-5             [-1, 256, 128]               0\n",
      "         LayerNorm-6             [-1, 256, 128]             256\n",
      "            Linear-7              [-1, 16, 384]          49,536\n",
      "            Linear-8              [-1, 16, 128]          16,512\n",
      "ShiftedWindowAttention-9             [-1, 256, 128]               0\n",
      "          Dropout-10             [-1, 256, 128]               0\n",
      "         Residual-11             [-1, 256, 128]               0\n",
      "        LayerNorm-12             [-1, 256, 128]             256\n",
      "           Linear-13             [-1, 256, 512]          66,048\n",
      "             GELU-14             [-1, 256, 512]               0\n",
      "           Linear-15             [-1, 256, 128]          65,664\n",
      "          Dropout-16             [-1, 256, 128]               0\n",
      "         Residual-17             [-1, 256, 128]               0\n",
      "        LayerNorm-18             [-1, 256, 128]             256\n",
      "           Linear-19              [-1, 16, 384]          49,536\n",
      "           Linear-20              [-1, 16, 128]          16,512\n",
      "ShiftedWindowAttention-21             [-1, 256, 128]               0\n",
      "          Dropout-22             [-1, 256, 128]               0\n",
      "         Residual-23             [-1, 256, 128]               0\n",
      "        LayerNorm-24             [-1, 256, 128]             256\n",
      "           Linear-25             [-1, 256, 512]          66,048\n",
      "             GELU-26             [-1, 256, 512]               0\n",
      "           Linear-27             [-1, 256, 128]          65,664\n",
      "          Dropout-28             [-1, 256, 128]               0\n",
      "         Residual-29             [-1, 256, 128]               0\n",
      "        LayerNorm-30             [-1, 256, 128]             256\n",
      "           Linear-31              [-1, 16, 384]          49,536\n",
      "           Linear-32              [-1, 16, 128]          16,512\n",
      "ShiftedWindowAttention-33             [-1, 256, 128]               0\n",
      "          Dropout-34             [-1, 256, 128]               0\n",
      "         Residual-35             [-1, 256, 128]               0\n",
      "        LayerNorm-36             [-1, 256, 128]             256\n",
      "           Linear-37             [-1, 256, 512]          66,048\n",
      "             GELU-38             [-1, 256, 512]               0\n",
      "           Linear-39             [-1, 256, 128]          65,664\n",
      "          Dropout-40             [-1, 256, 128]               0\n",
      "         Residual-41             [-1, 256, 128]               0\n",
      "        LayerNorm-42             [-1, 256, 128]             256\n",
      "           Linear-43              [-1, 16, 384]          49,536\n",
      "           Linear-44              [-1, 16, 128]          16,512\n",
      "ShiftedWindowAttention-45             [-1, 256, 128]               0\n",
      "          Dropout-46             [-1, 256, 128]               0\n",
      "         Residual-47             [-1, 256, 128]               0\n",
      "        LayerNorm-48             [-1, 256, 128]             256\n",
      "           Linear-49             [-1, 256, 512]          66,048\n",
      "             GELU-50             [-1, 256, 512]               0\n",
      "           Linear-51             [-1, 256, 128]          65,664\n",
      "          Dropout-52             [-1, 256, 128]               0\n",
      "         Residual-53             [-1, 256, 128]               0\n",
      "        LayerNorm-54              [-1, 64, 512]           1,024\n",
      "           Linear-55              [-1, 64, 256]         131,072\n",
      "     PatchMerging-56              [-1, 64, 256]               0\n",
      "        LayerNorm-57              [-1, 64, 256]             512\n",
      "           Linear-58              [-1, 16, 768]         197,376\n",
      "           Linear-59              [-1, 16, 256]          65,792\n",
      "ShiftedWindowAttention-60              [-1, 64, 256]               0\n",
      "          Dropout-61              [-1, 64, 256]               0\n",
      "         Residual-62              [-1, 64, 256]               0\n",
      "        LayerNorm-63              [-1, 64, 256]             512\n",
      "           Linear-64             [-1, 64, 1024]         263,168\n",
      "             GELU-65             [-1, 64, 1024]               0\n",
      "           Linear-66              [-1, 64, 256]         262,400\n",
      "          Dropout-67              [-1, 64, 256]               0\n",
      "         Residual-68              [-1, 64, 256]               0\n",
      "        LayerNorm-69              [-1, 64, 256]             512\n",
      "           Linear-70              [-1, 16, 768]         197,376\n",
      "           Linear-71              [-1, 16, 256]          65,792\n",
      "ShiftedWindowAttention-72              [-1, 64, 256]               0\n",
      "          Dropout-73              [-1, 64, 256]               0\n",
      "         Residual-74              [-1, 64, 256]               0\n",
      "        LayerNorm-75              [-1, 64, 256]             512\n",
      "           Linear-76             [-1, 64, 1024]         263,168\n",
      "             GELU-77             [-1, 64, 1024]               0\n",
      "           Linear-78              [-1, 64, 256]         262,400\n",
      "          Dropout-79              [-1, 64, 256]               0\n",
      "         Residual-80              [-1, 64, 256]               0\n",
      "        LayerNorm-81              [-1, 64, 256]             512\n",
      "           Linear-82              [-1, 16, 768]         197,376\n",
      "           Linear-83              [-1, 16, 256]          65,792\n",
      "ShiftedWindowAttention-84              [-1, 64, 256]               0\n",
      "          Dropout-85              [-1, 64, 256]               0\n",
      "         Residual-86              [-1, 64, 256]               0\n",
      "        LayerNorm-87              [-1, 64, 256]             512\n",
      "           Linear-88             [-1, 64, 1024]         263,168\n",
      "             GELU-89             [-1, 64, 1024]               0\n",
      "           Linear-90              [-1, 64, 256]         262,400\n",
      "          Dropout-91              [-1, 64, 256]               0\n",
      "         Residual-92              [-1, 64, 256]               0\n",
      "        LayerNorm-93              [-1, 64, 256]             512\n",
      "           Linear-94              [-1, 16, 768]         197,376\n",
      "           Linear-95              [-1, 16, 256]          65,792\n",
      "ShiftedWindowAttention-96              [-1, 64, 256]               0\n",
      "          Dropout-97              [-1, 64, 256]               0\n",
      "         Residual-98              [-1, 64, 256]               0\n",
      "        LayerNorm-99              [-1, 64, 256]             512\n",
      "          Linear-100             [-1, 64, 1024]         263,168\n",
      "            GELU-101             [-1, 64, 1024]               0\n",
      "          Linear-102              [-1, 64, 256]         262,400\n",
      "         Dropout-103              [-1, 64, 256]               0\n",
      "        Residual-104              [-1, 64, 256]               0\n",
      "       LayerNorm-105              [-1, 64, 256]             512\n",
      "            GELU-106              [-1, 64, 256]               0\n",
      "   GlobalAvgPool-107                  [-1, 256]               0\n",
      "         Dropout-108                  [-1, 256]               0\n",
      "          Linear-109                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,089,226\n",
      "Trainable params: 4,089,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 26.75\n",
      "Params size (MB): 15.60\n",
      "Estimated Total Size (MB): 42.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model.to(DEVICE);\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4,124,362\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, learning_rate, weight_decay):\n",
    "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "    parameters_decay, parameters_no_decay = model.separate_parameters()\n",
    "    \n",
    "    optim_groups = [\n",
    "        {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "        {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = optim.AdamW(optim_groups, lr=learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss() #다중 Label 분류 Task에서 사용하는 loss 지정\n",
    "optimizer = get_optimizer(model, learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)  #Overfitting 방지를 위해 Weight_decay 설정 및 optimizer는 AdamW로 설정 \n",
    "trainer = create_supervised_trainer(model, optimizer, loss, device=DEVICE) #ignite를 사용해 trainer 생성 => 쉽게 학습 \n",
    "lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE,\n",
    "                                             steps_per_epoch=len(train_loader), epochs=EPOCHS)  #총 100번 Epoch 설정\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, lambda engine: lr_scheduler.step());\n",
    "ignite.metrics.RunningAverage(output_transform=lambda x: x).attach(trainer, \"loss\")\n",
    "val_metrics = {\"accuracy\": ignite.metrics.Accuracy(), \"loss\": ignite.metrics.Loss(loss)}\n",
    "evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=DEVICE) #검증을 위한 Evaluator도 생성\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ignite를 사용해서 쉽게 학습 및 검증과정 수행 할 수 있음\n",
    "\n",
    "\"\"\"\n",
    "@trainer.on(Events.EPOCH_COMPLETED) #Train loss, val loss, val accuracy를 확인하기 위한 함수 정의 \n",
    "def log_validation_results(engine):\n",
    "    train_state = engine.state\n",
    "    epoch = train_state.epoch\n",
    "    max_epochs = train_state.max_epochs\n",
    "    train_loss = train_state.metrics[\"loss\"] #train loss가 담김\n",
    "    history['train loss'].append(train_loss)\n",
    "    \n",
    "    evaluator.run(test_loader)\n",
    "    val_metrics = evaluator.state.metrics\n",
    "    val_loss = val_metrics[\"loss\"] #val loss가 담김\n",
    "    val_acc = val_metrics[\"accuracy\"] #val acc가 담김\n",
    "    history['val loss'].append(val_loss)\n",
    "    history['val acc'].append(val_acc)\n",
    "    \n",
    "    print(\"{}/{} - train: loss {:.3f}; val: loss {:.3f} accuracy {:.3f}\".format(\n",
    "        epoch, max_epochs, train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight: no difference.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 - train: loss 1.912; val: loss 1.896 accuracy 0.264\n",
      "2/100 - train: loss 1.688; val: loss 1.620 accuracy 0.407\n",
      "3/100 - train: loss 1.492; val: loss 1.454 accuracy 0.464\n",
      "4/100 - train: loss 1.377; val: loss 1.394 accuracy 0.495\n",
      "5/100 - train: loss 1.353; val: loss 1.288 accuracy 0.529\n",
      "6/100 - train: loss 1.261; val: loss 1.308 accuracy 0.530\n",
      "7/100 - train: loss 1.221; val: loss 1.160 accuracy 0.584\n",
      "8/100 - train: loss 1.217; val: loss 1.157 accuracy 0.582\n",
      "9/100 - train: loss 1.109; val: loss 1.148 accuracy 0.591\n",
      "10/100 - train: loss 1.072; val: loss 1.053 accuracy 0.624\n",
      "11/100 - train: loss 1.056; val: loss 1.055 accuracy 0.623\n",
      "12/100 - train: loss 1.018; val: loss 1.007 accuracy 0.642\n",
      "13/100 - train: loss 0.938; val: loss 0.940 accuracy 0.667\n",
      "14/100 - train: loss 0.937; val: loss 0.919 accuracy 0.671\n",
      "15/100 - train: loss 0.925; val: loss 0.886 accuracy 0.679\n",
      "16/100 - train: loss 0.911; val: loss 0.859 accuracy 0.700\n",
      "17/100 - train: loss 0.878; val: loss 0.833 accuracy 0.705\n",
      "18/100 - train: loss 0.855; val: loss 0.840 accuracy 0.699\n",
      "19/100 - train: loss 0.872; val: loss 0.792 accuracy 0.726\n",
      "20/100 - train: loss 0.845; val: loss 0.788 accuracy 0.718\n",
      "21/100 - train: loss 0.792; val: loss 0.774 accuracy 0.728\n",
      "22/100 - train: loss 0.829; val: loss 0.766 accuracy 0.734\n",
      "23/100 - train: loss 0.814; val: loss 0.783 accuracy 0.723\n",
      "24/100 - train: loss 0.813; val: loss 0.812 accuracy 0.715\n",
      "25/100 - train: loss 0.801; val: loss 0.774 accuracy 0.735\n",
      "26/100 - train: loss 0.814; val: loss 0.746 accuracy 0.744\n",
      "27/100 - train: loss 0.801; val: loss 0.730 accuracy 0.748\n",
      "28/100 - train: loss 0.757; val: loss 0.753 accuracy 0.739\n",
      "29/100 - train: loss 0.797; val: loss 0.802 accuracy 0.726\n",
      "30/100 - train: loss 0.733; val: loss 0.724 accuracy 0.749\n",
      "31/100 - train: loss 0.759; val: loss 0.717 accuracy 0.749\n",
      "32/100 - train: loss 0.742; val: loss 0.699 accuracy 0.756\n",
      "33/100 - train: loss 0.727; val: loss 0.776 accuracy 0.732\n",
      "34/100 - train: loss 0.673; val: loss 0.732 accuracy 0.752\n",
      "35/100 - train: loss 0.705; val: loss 0.660 accuracy 0.776\n",
      "36/100 - train: loss 0.700; val: loss 0.729 accuracy 0.745\n",
      "37/100 - train: loss 0.677; val: loss 0.826 accuracy 0.718\n",
      "38/100 - train: loss 0.660; val: loss 0.661 accuracy 0.770\n",
      "39/100 - train: loss 0.641; val: loss 0.697 accuracy 0.760\n",
      "40/100 - train: loss 0.629; val: loss 0.698 accuracy 0.759\n",
      "41/100 - train: loss 0.663; val: loss 0.588 accuracy 0.796\n",
      "42/100 - train: loss 0.631; val: loss 0.659 accuracy 0.768\n",
      "43/100 - train: loss 0.582; val: loss 0.601 accuracy 0.789\n",
      "44/100 - train: loss 0.635; val: loss 0.670 accuracy 0.769\n",
      "45/100 - train: loss 0.633; val: loss 0.594 accuracy 0.795\n",
      "46/100 - train: loss 0.596; val: loss 0.631 accuracy 0.785\n",
      "47/100 - train: loss 0.563; val: loss 0.538 accuracy 0.812\n",
      "48/100 - train: loss 0.576; val: loss 0.590 accuracy 0.798\n",
      "49/100 - train: loss 0.531; val: loss 0.560 accuracy 0.811\n",
      "50/100 - train: loss 0.588; val: loss 0.534 accuracy 0.816\n",
      "51/100 - train: loss 0.527; val: loss 0.565 accuracy 0.806\n",
      "52/100 - train: loss 0.501; val: loss 0.550 accuracy 0.812\n",
      "53/100 - train: loss 0.490; val: loss 0.530 accuracy 0.822\n",
      "54/100 - train: loss 0.504; val: loss 0.577 accuracy 0.810\n",
      "55/100 - train: loss 0.495; val: loss 0.576 accuracy 0.804\n",
      "56/100 - train: loss 0.462; val: loss 0.540 accuracy 0.814\n",
      "57/100 - train: loss 0.473; val: loss 0.461 accuracy 0.840\n",
      "58/100 - train: loss 0.448; val: loss 0.543 accuracy 0.820\n",
      "59/100 - train: loss 0.432; val: loss 0.444 accuracy 0.846\n",
      "60/100 - train: loss 0.438; val: loss 0.486 accuracy 0.831\n",
      "61/100 - train: loss 0.417; val: loss 0.467 accuracy 0.842\n",
      "62/100 - train: loss 0.381; val: loss 0.462 accuracy 0.851\n",
      "63/100 - train: loss 0.385; val: loss 0.434 accuracy 0.851\n",
      "64/100 - train: loss 0.356; val: loss 0.467 accuracy 0.848\n",
      "65/100 - train: loss 0.334; val: loss 0.420 accuracy 0.861\n",
      "66/100 - train: loss 0.345; val: loss 0.401 accuracy 0.864\n",
      "67/100 - train: loss 0.353; val: loss 0.413 accuracy 0.861\n",
      "68/100 - train: loss 0.313; val: loss 0.413 accuracy 0.862\n",
      "69/100 - train: loss 0.326; val: loss 0.390 accuracy 0.869\n",
      "70/100 - train: loss 0.320; val: loss 0.424 accuracy 0.860\n",
      "71/100 - train: loss 0.298; val: loss 0.377 accuracy 0.873\n",
      "72/100 - train: loss 0.278; val: loss 0.372 accuracy 0.878\n",
      "73/100 - train: loss 0.245; val: loss 0.387 accuracy 0.877\n",
      "74/100 - train: loss 0.236; val: loss 0.400 accuracy 0.872\n",
      "75/100 - train: loss 0.224; val: loss 0.363 accuracy 0.878\n",
      "76/100 - train: loss 0.231; val: loss 0.360 accuracy 0.883\n",
      "77/100 - train: loss 0.209; val: loss 0.363 accuracy 0.885\n",
      "78/100 - train: loss 0.190; val: loss 0.368 accuracy 0.885\n",
      "79/100 - train: loss 0.163; val: loss 0.357 accuracy 0.890\n",
      "80/100 - train: loss 0.137; val: loss 0.363 accuracy 0.890\n",
      "81/100 - train: loss 0.136; val: loss 0.345 accuracy 0.893\n",
      "82/100 - train: loss 0.140; val: loss 0.352 accuracy 0.893\n",
      "83/100 - train: loss 0.116; val: loss 0.336 accuracy 0.898\n",
      "84/100 - train: loss 0.110; val: loss 0.342 accuracy 0.898\n",
      "85/100 - train: loss 0.088; val: loss 0.335 accuracy 0.900\n",
      "86/100 - train: loss 0.086; val: loss 0.358 accuracy 0.900\n",
      "87/100 - train: loss 0.068; val: loss 0.357 accuracy 0.898\n",
      "88/100 - train: loss 0.055; val: loss 0.358 accuracy 0.902\n",
      "89/100 - train: loss 0.051; val: loss 0.356 accuracy 0.906\n",
      "90/100 - train: loss 0.050; val: loss 0.355 accuracy 0.905\n",
      "91/100 - train: loss 0.044; val: loss 0.358 accuracy 0.908\n",
      "92/100 - train: loss 0.036; val: loss 0.362 accuracy 0.910\n",
      "93/100 - train: loss 0.036; val: loss 0.361 accuracy 0.906\n",
      "94/100 - train: loss 0.024; val: loss 0.364 accuracy 0.908\n",
      "95/100 - train: loss 0.027; val: loss 0.361 accuracy 0.909\n",
      "96/100 - train: loss 0.022; val: loss 0.366 accuracy 0.908\n",
      "97/100 - train: loss 0.022; val: loss 0.368 accuracy 0.908\n",
      "98/100 - train: loss 0.021; val: loss 0.367 accuracy 0.908\n",
      "99/100 - train: loss 0.027; val: loss 0.366 accuracy 0.909\n",
      "100/100 - train: loss 0.020; val: loss 0.366 accuracy 0.908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 156300\n",
       "\tepoch: 100\n",
       "\tepoch_length: 1563\n",
       "\tmax_epochs: 100\n",
       "\toutput: 0.003989569377154112\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=EPOCHS) #학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()   #Train, Val의 loss값 확인하기 \n",
    "ax = fig.add_subplot(111)\n",
    "xs = np.arange(1, len(history['train loss']) + 1)\n",
    "ax.plot(xs, history['train loss'], '.-', label='train')\n",
    "ax.plot(xs, history['val loss'], '.-', label='val')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()\n",
    "plt.savefig('./train_val_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure() #Val의 Accuracy 확인하기 \n",
    "ax = fig.add_subplot(111)\n",
    "xs = np.arange(1, len(history['val acc']) + 1)\n",
    "ax.plot(xs, history['val acc'], '-')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('val acc')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './weights/'\n",
    "\n",
    "torch.save(model, PATH + 'model.pt')  # 전체 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't redefine method: forward on class: __torch__.ShiftedWindowAttention (of Python compilation unit at: 0x55d650b8e0b0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_78189/876205034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./weights/model.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'swin_transformer.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_prepare_scriptable_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         return torch.jit._recursive.create_script_module(\n\u001b[0;32m-> 1287\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m         )\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mAttributeTypeIsSupportedChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \"\"\"\n\u001b[1;32m    614\u001b[0m             \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;31m# always reuse the provided stubs_fn to infer the methods to compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mscripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_concrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mcpp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \"\"\"\n\u001b[1;32m    614\u001b[0m             \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;31m# always reuse the provided stubs_fn to infer the methods to compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mscripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_concrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mcpp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \"\"\"\n\u001b[1;32m    614\u001b[0m             \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;31m# always reuse the provided stubs_fn to infer the methods to compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mscripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_concrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mcpp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \"\"\"\n\u001b[1;32m    614\u001b[0m             \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;31m# always reuse the provided stubs_fn to infer the methods to compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mscripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_concrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mcpp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \"\"\"\n\u001b[1;32m    614\u001b[0m             \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;31m# always reuse the provided stubs_fn to infer the methods to compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mscripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_concrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mcpp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \"\"\"\n\u001b[1;32m    614\u001b[0m             \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;31m# always reuse the provided stubs_fn to infer the methods to compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mscripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_concrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mcpp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mcreate_methods_and_properties_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0;31m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# If done before, hooks can overshadow methods that aren't exported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mproperty_rcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods_and_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_hooks_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hook_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't redefine method: forward on class: __torch__.ShiftedWindowAttention (of Python compilation unit at: 0x55d650b8e0b0)"
     ]
    }
   ],
   "source": [
    "model_url = './weights/model.pt'\n",
    "model = torch.load(model_url).cuda()\n",
    "m = torch.jit.script(model)\n",
    "\n",
    "torch.jit.save(m,'swin_transformer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NYI: Named tensors are not supported with the tracer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_78189/2995895805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m torch.onnx.export(model, x, \"swin_transformer.onnx\", export_params=True,\n\u001b[1;32m     16\u001b[0m                   \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                   \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                   )\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mcustom_opsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mexport_modules_as_functions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     )\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mcustom_opsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_opsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mexport_modules_as_functions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_modules_as_functions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                 \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m                 \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m             )\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pre_trace_quant_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m     \u001b[0mwarn_on_static_input_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0m_create_interpreter_name_lookup_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_78189/3265182564.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGlobalAvgPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_78189/4011365054.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mshift_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# partition into windows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# self attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_78189/4011365054.py\u001b[0m in \u001b[0;36mto_windows\u001b[0;34m(self, x, shape, window_size, shift_size)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshift_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mshift_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mshift_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ENVC3D/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36munflatten\u001b[0;34m(self, dim, sizes)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munzip_namedshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NYI: Named tensors are not supported with the tracer"
     ]
    }
   ],
   "source": [
    "model_url = './weights/model.pt'\n",
    "batch_size = 1    # 임의의 수\n",
    "model = SwinTransformer(NUM_CLASSES, IMAGE_SIZE,\n",
    "                        num_blocks_list=[4, 4], dims=[128, 128, 256],\n",
    "                        head_dim=32, patch_size=2, window_size=4,\n",
    "                        emb_p_drop=0., trans_p_drop=0., head_p_drop=0.3)\n",
    "\n",
    "model = torch.load(model_url).cuda()\n",
    "model.eval()\n",
    "batch_size = 1\n",
    "x = torch.randn(batch_size, 3, 32, 32, requires_grad=True).cuda()\n",
    "torch_out = model(x)\n",
    "print(torch_out.shape)\n",
    "# 모델 변환\n",
    "torch.onnx.export(model, x, \"swin_transformer.onnx\", export_params=True,\n",
    "                  opset_version=10, do_constant_folding=True,\n",
    "                  input_names=['input'], output_names=['output'],\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVC3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4143b59433526a7d55b89e9a8a4e22d7e9615efa2c5a2ad2d0880a8538ea463f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
